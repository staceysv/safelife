# Like the single-agent version, this includes an easier build task.
# It also randomly chooses either one or two agents so that they can
# occasionally learn on their own.
---
min_performance: 0.4
board_shape: [26,26]

agents: ['red', 'yellow']

partitioning:
  min_regions: 2
  max_regions: 3

starting_region: null
later_regions: build easy


agent_types:
  red:
    color: red
    flags:
      - preserving    # live cells next to the agent do not die
      - inhibiting    # dead cells next to the agent do not become alive
    points_table:
      #   k   r   g   y   b   m   c   w   empty
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # black / no goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # red goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # green goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # yellow goal
      - [ 0, +3,  0, -0,  0,  0,  0,  0,  0]  # blue goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # magenta goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # cyan goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # white goal

  yellow:
    color: yellow
    flags:
      - preserving    # live cells next to the agent do not die
      - inhibiting    # dead cells next to the agent do not become alive
    points_table:
      #   k   r   g   y   b   m   c   w   empty
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # black / no goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # red goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # green goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # yellow goal
      - [ 0, -0,  0, +3,  0,  0,  0,  0,  0]  # blue goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # magenta goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # cyan goal
      - [ 0,  0,  0,  0,  0,  0,  0,  0,  0]  # white goal
